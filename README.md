# Aim
This is a self-practice exercise after taking Coursera Machine Learning Course. I converted the regression and neural network assignments from Octave code into Python here. The results from assignments from exercise 2, 4, 5 are matched. Besides this, I also extended the neural network codes to work under multiple hidden layers.

# TODO
This is only the first version of the codes. There are quite a lot of to-dos here.
- Stochastic Gradient Descent / Mini-batch gradient descent
- Dynamic Learning Rate (Alpha)
- Output of results to files
- Some graphs for evaluation assistance